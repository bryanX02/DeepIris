{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afaccae9-6ae0-437c-ab28-7f9922b24109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 22:14:53.131168: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-25 22:14:53.174998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-25 22:14:54.654345: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n",
      "GPU Detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Matrix multiplication on GPU:\n",
      " [[1. 3.]\n",
      " [3. 7.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761423296.353390    5876 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5580 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# Check for GPU\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU Detected:\", gpu_devices)\n",
    "    # Simple calculation on GPU\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "    print(\"Matrix multiplication on GPU:\\n\", c.numpy())\n",
    "else:\n",
    "    print(\"GPU NOT Detected. Using CPU.\")\n",
    "    # Simple calculation on CPU\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"Matrix multiplication on CPU:\\n\", c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b386cb-f74e-4f32-82bc-c52a75cfd3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Hugging Face Transformers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Result: [{'label': 'POSITIVE', 'score': 0.9998533725738525}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "print(\"Testing Hugging Face Transformers...\")\n",
    "# Load a simple pipeline (will download model on first run)\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "result = classifier('This TFG is going great!')\n",
    "print(\"Sentiment Analysis Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf0487b-4bb3-4fb9-8693-20be915bf166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version: 4.12.0\n",
      "OpenCV test successful: Created a dummy image and drew a line.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"OpenCV Version:\", cv2.__version__)\n",
    "\n",
    "# Create a simple black image (100x100 pixels)\n",
    "dummy_image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw a white line on it\n",
    "cv2.line(dummy_image, (10, 10), (90, 90), (255, 255, 255), thickness=2)\n",
    "\n",
    "print(\"OpenCV test successful: Created a dummy image and drew a line.\")\n",
    "# Optional: Display the image if you have matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(dummy_image)\n",
    "# plt.title(\"OpenCV Test\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdf191-799f-47a5-9bf2-f9ea60128725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
